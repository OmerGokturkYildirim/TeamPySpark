{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import plotly as pl\n",
    "import matplotlib.pyplot as plt\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import ClusterCentroids\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = Path('C:/Users/esobieski/Documents/Berkeley/TeamPySpark/loans.csv')\n",
    "# df = pd.read_csv(file_path, skiprows=1)[:-2]\n",
    "# df = df.loc[:, columns].copy()\n",
    "loans_df = pd.read_csv(file_path)  # Can ddd in ( , index_col=0) if need to say which col becomes index\n",
    "loans_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index\n",
    "loans_df.set_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all column names\n",
    "loans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name variables to find time elapsed from when request was posted to when it was funded.\n",
    "raised_time = pd.to_datetime(loans_df[\"RAISED_TIME\"])\n",
    "posted_time = pd.to_datetime(loans_df[\"POSTED_TIME\"])\n",
    "elapsed_time_df = raised_time - posted_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of elapsed time amounts\n",
    "elapsed_time_df.astype(\"timedelta64[D]\").hist(range=[-5, 25])\n",
    "# 12 days is our cutoff for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats for elapsed time\n",
    "elapsed_time_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO REMOVE TIME OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up a function for converting strings to number objects\n",
    "\n",
    "loans_df.BORROWER_GENDERS.astype(str)\n",
    "\n",
    "test_string = \"female, female, female, female, female, female\"\n",
    "\n",
    "def female(txt):\n",
    "    lst = txt.split(\", \")\n",
    "    count = 0\n",
    "    for x in lst:\n",
    "        if x == \"female\":\n",
    "            count +=1 \n",
    "    return count\n",
    "\n",
    "def male(txt):\n",
    "    lst = txt.split(\", \")\n",
    "    count = 0\n",
    "    for x in lst:\n",
    "        if x == \"male\":\n",
    "            count +=1 \n",
    "    return count\n",
    "\n",
    "female(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a working copy of the loans_df dataframe\n",
    "working_loans_df = loans_df.set_index\n",
    "working_loans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the gender column in working_loans_df\n",
    "working_loans_df = loans_df['BORROWER_GENDERS'].dropna()\n",
    "working_loans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datatypes for gender to string\n",
    "working_loans_df.astype(str)\n",
    "#working_loans_df.set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the male and female gender functions to the dataset, yields a number value for each field. \n",
    "# The results are the next cell.\n",
    "#new_df = working_loans_df.set_index\n",
    "new_df = working_loans_df.apply(male)\n",
    "new_df2 = working_loans_df.apply(female)\n",
    "new_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The result of gender counting is that 1.245 million values are female, \n",
    "#408,585 values are male, and only 246,605 data points are groups.  \n",
    "\n",
    "new_df2.value_counts()\n",
    "\n",
    "#Recommendations to consider:\n",
    "# Reassign all values 2 or greater to a group\n",
    "# Drop all group values to simply the data.\n",
    "# Decision point here! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender distrubtion histogram.  0 is male, 1 is female, long tail are groups of varying composition.\n",
    "new_df2.hist(range=[-5, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original df counts to compare to function results to make sure transformation did not alter data\n",
    "loans_df['BORROWER_GENDERS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMBINE ALL VALUES GREATER THAN 2 TO GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gender dataframe converted to numbers back into the database.\n",
    "loans_new_df = loans_df.update(new_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender values are now numeric\n",
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at elapsed time dataframe\n",
    "elapsed_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a new column with days from request to funding completion\n",
    "#loans_new_df = loans_df.append(elapsed_time_df, ignore_index = True)\n",
    "#loans_new_df\n",
    "loans_df['FUNDING_TIME'] = elapsed_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm that Time to funding was added as a column to loans_df\n",
    "loans_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping all unneeded columns \n",
    "#DOES THIS NEEDS TO BE UPDATED SO WE DON'T REMOVE TOO MUCH?  ???SHOUD WE BE REMOVING CURRENCY, REPAYMENT_INTERVAL???\n",
    "loans_df.drop(['LOAN_ID', 'LOAN_NAME', 'DESCRIPTION','DESCRIPTION_TRANSLATED','IMAGE_ID', 'VIDEO_ID', 'LOAN_USE','COUNTRY_CODE', 'TOWN_NAME', 'CURRENCY_POLICY',\n",
    "       'CURRENCY_EXCHANGE_COVERAGE_RATE', 'CURRENCY', 'PARTNER_ID', 'POSTED_TIME', 'PLANNED_EXPIRATION_TIME', 'DISBURSE_TIME','RAISED_TIME', 'LENDER_TERM', 'NUM_JOURNAL_ENTRIES', 'NUM_BULK_ENTRIES', 'BORROWER_NAMES','BORROWER_PICTURED', 'REPAYMENT_INTERVAL','DISTRIBUTION_MODEL'], axis=1, inplace=True)\n",
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving tags column as a df  FOR FUTURE USE IN NATURAL LANUGUAGE PROCESSING ANALYSIS\n",
    "tags_df = pd.DataFrame(loans_df[\"TAGS\"])\n",
    "tags_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick a sample of the data as using all did not work for get dummies (10% used) ??? LOOKS LIKE 1%???\n",
    "model_df = loans_df.sample(frac =.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For logistic regression, our binary classification is that a successful borrowing event results in full funding within 12 days.  An unsucessful event would be funding taking longer than 12 days, as a reflection of less lender enthusiasm to fund the loan.  This removes the issue in the data that 99%+ of loans get funded and thus the data is very unbalanced if you just look at funding vs didn't fund.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features  NOT SURE ABOUT THIS VS THE TRAINING AND TESTING A FEW CELLS DOWN\n",
    "\n",
    "X = model_df.copy()\n",
    "X = X.drop('STATUS', axis=1)\n",
    "\n",
    "# Create our target\n",
    "y = model_df[['STATUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe X\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List out y\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of our target values  \n",
    "# Used a calculated value of TIME TO FULL FUNDING using date stamps in prep for LOGISTIC REGRESSION\n",
    "\n",
    "y['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Labels (DO WE USE THIS OR ONE HOT ENCODER?)\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TRAIN-TEST SPLIT AFTER GETTING DUMMIES AND BEFORE SCALING, SO RIGHT HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALING STEP HERE\n",
    "loans_scaled = StandardScaler().fit_transform(X)\n",
    "print(loans_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA model intialization (can compare with 500 components)\n",
    "pca = PCA(n_components=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA fit\n",
    "loans_pca = pca.fit_transform(loans_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform PCA data to a DataFrame \n",
    "pca_df = pd.DataFrame(data=loans_pca, columns=[\"PC 1\", \"PC 2\", \"PC 3\", \"PC 4\", \"PC 5\"])\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create k means model \n",
    "# *CAN USE OTHER MODELS ASIDE FROM K MEANS, AFTER PCA.  \n",
    "# If English was a determinant, like language, then you need to have all languages to make the info complete.\n",
    "# Or other category is \"other languages\", or top 3.  Or use Random Forest which takes in weak relationships and makes them stronger.\n",
    "# Best to try every model we learned in the module.\n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "# Calculate the inertia for the range of K values\n",
    "for i in k:\n",
    "   km = KMeans(n_clusters=i, random_state=0)\n",
    "   km.fit(pcs_df)\n",
    "   inertia.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create elbow curve using hvPlot\n",
    "elbow_data = {\"k\" : k, \"inertia\":inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", xticks=k, title=\"Elbow Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-means model\n",
    "model = KMeans(n_clusters=3, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "predictions = model.predict(pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "pcs_df[\"class\"] = model.labels_\n",
    "pcs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clustered df \n",
    "clustered_df = pd.merge(model_df, pcs_df, left_index=True, right_index=True)\n",
    "clustered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED SCREENSHOT OF THE PLOT FOR LATER BECAUSE THE GRADERS DON'T HAVE THE DATASET\n",
    "# Plot the 3D-scatter\n",
    "fig = px.scatter_3d(\n",
    "clustered_df,\n",
    "x=\"LOAN_AMOUNT\",\n",
    "y=\"FUNDING_TIME\",\n",
    "z=\"BORROWER_GENDERS\",\n",
    "color=\"class\",\n",
    "symbol=\"class\",\n",
    "hover_name=\"STATUS\",\n",
    "hover_data=[\"COUNTRY_NAME\"],\n",
    "width=800,)\n",
    "\n",
    "fig.update_layout(legend=dict(x=0, y=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO RUN CONFUSION MATRIX ON PREDICTED CLUSTERS *AND* ORIGINAL Y VALUES, NOT THE K-MEANS Y VALUES.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hvplot scatter plot to view relationship\n",
    "clustered_df.hvplot.scatter(\n",
    "    x=\"COUNTRY_NAME\",\n",
    "    y=\"FUNDING_TIME\",\n",
    "    by=\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Logistic Regression on FUNDING_TIME and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SVMs using PCA 1,000 components and Epsilon SVR and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run NLP on Tags DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
